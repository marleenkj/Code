{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'boto3'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mboto3\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mloguru\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logger\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'boto3'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from loguru import logger\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import s3fs\n",
    "import sqlalchemy\n",
    "from sqlalchemy import text\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import LineString\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.preprocessing import data_preprocessing_nshift, data_preprocessing_bridge\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "project_path = 's3://sfgdata/projects/sustainable-transport'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary for column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import s3fs\n",
    "import json\n",
    "\n",
    "# here for oerebro dataset\n",
    "project_path = 's3://sfgdata/projects/sustainable-transport'\n",
    "dict_column_names = 'bridge_names'\n",
    "\n",
    "client = boto3.client('location')\n",
    "s3 = s3fs.S3FileSystem()\n",
    "\n",
    "\n",
    "with s3.open(f'{project_path}/external/nshift_names.json', 'r') as fp:\n",
    "    dict_names = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Pickup date': 'Pickup date',\n",
       " 'Client no': 'Receiver reference',\n",
       " 'DC name': 'Actor',\n",
       " 'Client name': 'Receiver',\n",
       " 'Address': 'Receiver address',\n",
       " 'Zip': 'Receiver zip',\n",
       " 'City': 'Receiver city',\n",
       " 'Country code': 'Receiver country code',\n",
       " 'Carrier name': 'Carrier',\n",
       " 'Sender weight (kg)': 'Sender weight (kg)',\n",
       " 'Volume (m3)': 'Sender volume (l)',\n",
       " 'Nb of packages': 'Number of packages'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_names = {'Pickup date': 'ABF',\n",
    "'DC code': 'TPLST',\n",
    "'DC name': 'TPLSTLib',\n",
    "'Client no': 'KUNNZ',\n",
    "'Client name': 'KUNNZLib',\n",
    "'Address': 'Street',\n",
    "'Zip': 'PostCode',\n",
    "'City': 'City',\n",
    "'Country code': 'Country',\n",
    "'Shipping type': 'VSART',\n",
    "'Carrier code': 'TDLNR',\n",
    "'Carrier name': 'TDLNRLib',\n",
    "'Sender weight': 'YYBTGEW',\n",
    "'Volume': 'YYVOLUM',\n",
    "'Weight unit': 'YYGEWEI',\n",
    "'Volume unit': 'YYVOLEH',\n",
    "'Nb of packages': 'NbColis',\n",
    "'Shipment id': 'TKNUM',\n",
    "'Shipping point': 'VSTEL'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IdSysteme',\n",
       " 'TKNUM',\n",
       " 'SHTYP',\n",
       " 'SHTYPLib',\n",
       " 'TPLST',\n",
       " 'TPLSTLib',\n",
       " 'VSART',\n",
       " 'VSARTLib',\n",
       " 'VSBED',\n",
       " 'VSBEDLib',\n",
       " 'ROUTE',\n",
       " 'ABF',\n",
       " 'TDLNR',\n",
       " 'TDLNRLib',\n",
       " 'TSNUM',\n",
       " 'VSTEL',\n",
       " 'VSTELLib',\n",
       " 'KUNNZ',\n",
       " 'YYEXIDV',\n",
       " 'KUNNR',\n",
       " 'KUNAG',\n",
       " 'Sum_BTGEW',\n",
       " 'Sum_NTGEW',\n",
       " 'GEWEI',\n",
       " 'Sum_VOLUM',\n",
       " 'VOLEH',\n",
       " 'POSNR',\n",
       " 'PARVW',\n",
       " 'KUNNR1',\n",
       " 'PARNR',\n",
       " 'ADRNR',\n",
       " 'ABLAD',\n",
       " 'LAND1',\n",
       " 'NAME1',\n",
       " 'STREET',\n",
       " 'CITY1',\n",
       " 'POST_CODE1',\n",
       " 'REGION',\n",
       " 'COUNTRY']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_bridge_v2 = {'Pickup date': 'ABF',\n",
    "'DC code': 'TPLST',\n",
    "'DC name': 'TPLSTLib',\n",
    "'Client no': 'KUNNR',\n",
    "'Client name': 'NAME1',\n",
    "'Address': 'STREET',\n",
    "'Zip': 'POST_CODE1',\n",
    "'City': 'CITY1',\n",
    "'Country code': 'COUNTRY',\n",
    "'Shipping type': 'VSART',\n",
    "'Carrier code': 'TDLNR',\n",
    "'Carrier name': 'TDLNRLib',\n",
    "'Sender weight': 'Sum_BTGEW',\n",
    "'Volume': 'Sum_VOLUM',\n",
    "'Weight unit': 'GEWEI',\n",
    "'Volume unit': 'VOLEH',\n",
    "'Shipment id': 'TKNUM',\n",
    "'Shipping point code': 'VSTEL',\n",
    "'Shipping point': 'VSTELLib'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with s3.open(f'{project_path}/external/bridge_names.json', 'w') as fp:\n",
    "    json.dump(dict_names, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with s3.open(f'{project_path}/external/bridge_names_v2.json', 'w') as fp:\n",
    "    json.dump(dict_bridge_v2, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information about data:\n",
    "* Data from SAP stored in SQL database\n",
    "* Data from Nshift stored in S3 in the \"raw\" folder:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAP data in SQL database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data from SAP stored in SQL database:\n",
    "* POC1: filter_vsartlib = ('GRD groupage','GRD LTL','GRD FTL','Truck')\n",
    "* POC2: filter_vsartlib = ('GRD groupage','GRD LTL','GRD FTL','Truck', 'Shuttle', 'GRD Mono Parcel')\n",
    "* POC3: Merge of POC2 data and NShift data of Oerebro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'sql_poc4'\n",
    "df = pd.read_csv(f'{project_path}/raw/{dataset_name}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'sql_poc4'\n",
    "df = pd.read_csv(f'{project_path}/processed/{dataset_name}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = 's3://sfgdata/projects/sustainable-transport'\n",
    "dataset_name = 'poc4'\n",
    "\n",
    "df = pd.read_csv(f'{project_path}/processed/{dataset_name}.csv', \n",
    "                 low_memory=False,\n",
    "                 parse_dates=['Pickup date'], \n",
    "                 dtype={'DC zip': str, 'Zip': str}).sort_values(by='Pickup date')\n",
    "df = df.dropna(subset = ['Distance (km)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional: Loading data from SQL to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to s3\n",
    "odbc_connect = (\n",
    "    f\"DRIVER={os.getenv('SQL_DRIVER')};\" + \n",
    "    f\"SERVER={os.getenv('SQL_SERVER')};\" + \n",
    "    f\"PORT=1433;\" +\n",
    "    f\"DATABASE={os.getenv('SQL_DATABASE')};\" +\n",
    "    f\"UID={os.getenv('USER_NAME')};\" +\n",
    "    f\"PWD={os.getenv('PASSWORD')}\"\n",
    ")\n",
    "\n",
    "engine = sqlalchemy.create_engine(\"mssql+pyodbc:///?odbc_connect=%s\" % odbc_connect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_tplst = ('HU07','FR45','FR43')\n",
    "filter_vsartlib = ('GRD groupage','GRD LTL','GRD FTL','Truck','Shuttle','GRD Mono Parcel')\n",
    "filter_country = ('BE','EL','LT','PT','BG','ES','LU','RO','CZ','FR','HU','SI','DK','HR','MT','SK','DE','IT','NL','FI','EE','CY','AT','SE','IE','LV','PL')\n",
    "#filter_kunnz = 'ISNUMERIC([KUNNZ]) = 1'\n",
    "query = f'SELECT * FROM .[Perf].[vwTRP_Transport] WHERE TPLST IN {filter_tplst} AND VSARTLib IN {filter_vsartlib} AND COUNTRY IN {filter_country}'\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    query = text(query)\n",
    "    df = pd.read_sql_query(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IdSysteme</th>\n",
       "      <th>TKNUM</th>\n",
       "      <th>SHTYP</th>\n",
       "      <th>SHTYPLib</th>\n",
       "      <th>TPLST</th>\n",
       "      <th>TPLSTLib</th>\n",
       "      <th>VSART</th>\n",
       "      <th>VSARTLib</th>\n",
       "      <th>VSBED</th>\n",
       "      <th>VSBEDLib</th>\n",
       "      <th>ROUTE</th>\n",
       "      <th>ABF</th>\n",
       "      <th>TDLNR</th>\n",
       "      <th>TDLNRLib</th>\n",
       "      <th>TSNUM</th>\n",
       "      <th>VSTEL</th>\n",
       "      <th>VSTELLib</th>\n",
       "      <th>KUNNZ</th>\n",
       "      <th>YYEXIDV</th>\n",
       "      <th>KUNNR</th>\n",
       "      <th>KUNAG</th>\n",
       "      <th>Sum_BTGEW</th>\n",
       "      <th>Sum_NTGEW</th>\n",
       "      <th>GEWEI</th>\n",
       "      <th>Sum_VOLUM</th>\n",
       "      <th>VOLEH</th>\n",
       "      <th>POSNR</th>\n",
       "      <th>PARVW</th>\n",
       "      <th>KUNNR1</th>\n",
       "      <th>PARNR</th>\n",
       "      <th>ADRNR</th>\n",
       "      <th>ABLAD</th>\n",
       "      <th>LAND1</th>\n",
       "      <th>NAME1</th>\n",
       "      <th>STREET</th>\n",
       "      <th>CITY1</th>\n",
       "      <th>POST_CODE1</th>\n",
       "      <th>REGION</th>\n",
       "      <th>COUNTRY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156288</th>\n",
       "      <td>2</td>\n",
       "      <td>CS01167806</td>\n",
       "      <td>Z2G2</td>\n",
       "      <td>IG-MultiLeg-Out</td>\n",
       "      <td>FR43</td>\n",
       "      <td>DC Newlog</td>\n",
       "      <td>49</td>\n",
       "      <td>GRD groupage</td>\n",
       "      <td>Z7</td>\n",
       "      <td>Stock Order</td>\n",
       "      <td>FR3960</td>\n",
       "      <td>2022-01-11 19:39:00</td>\n",
       "      <td>0010043514</td>\n",
       "      <td>GEBRUDER WEISS GMBH</td>\n",
       "      <td>1</td>\n",
       "      <td>FR20</td>\n",
       "      <td>FR45-Standard</td>\n",
       "      <td>CSE00030</td>\n",
       "      <td>00636064800913463010</td>\n",
       "      <td>CSE00030</td>\n",
       "      <td>CSE00010</td>\n",
       "      <td>9264.0</td>\n",
       "      <td>8387.0</td>\n",
       "      <td>G</td>\n",
       "      <td>0.09</td>\n",
       "      <td>M3</td>\n",
       "      <td>0</td>\n",
       "      <td>WE</td>\n",
       "      <td>CSE00030</td>\n",
       "      <td>0</td>\n",
       "      <td>0000348619</td>\n",
       "      <td>POINT1</td>\n",
       "      <td>SE</td>\n",
       "      <td>SCHNEIDER ELECTRIC DISTRIBUTION CENTREAB</td>\n",
       "      <td>LASTGATAN</td>\n",
       "      <td>OREBRO</td>\n",
       "      <td>702 27</td>\n",
       "      <td>None</td>\n",
       "      <td>SE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        IdSysteme       TKNUM SHTYP         SHTYPLib TPLST   TPLSTLib VSART  \\\n",
       "156288          2  CS01167806  Z2G2  IG-MultiLeg-Out  FR43  DC Newlog    49   \n",
       "\n",
       "            VSARTLib VSBED     VSBEDLib   ROUTE                 ABF  \\\n",
       "156288  GRD groupage    Z7  Stock Order  FR3960 2022-01-11 19:39:00   \n",
       "\n",
       "             TDLNR             TDLNRLib  TSNUM VSTEL       VSTELLib     KUNNZ  \\\n",
       "156288  0010043514  GEBRUDER WEISS GMBH      1  FR20  FR45-Standard  CSE00030   \n",
       "\n",
       "                     YYEXIDV     KUNNR     KUNAG  Sum_BTGEW  Sum_NTGEW GEWEI  \\\n",
       "156288  00636064800913463010  CSE00030  CSE00010     9264.0     8387.0     G   \n",
       "\n",
       "        Sum_VOLUM VOLEH  POSNR PARVW    KUNNR1  PARNR       ADRNR   ABLAD  \\\n",
       "156288       0.09    M3      0    WE  CSE00030      0  0000348619  POINT1   \n",
       "\n",
       "       LAND1                                     NAME1     STREET   CITY1  \\\n",
       "156288    SE  SCHNEIDER ELECTRIC DISTRIBUTION CENTREAB  LASTGATAN  OREBRO   \n",
       "\n",
       "       POST_CODE1 REGION COUNTRY  \n",
       "156288     702 27   None      SE  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['VSTEL']=='FR20')&(df['TPLST']=='FR43')&(df['TKNUM']=='CS01167806')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>occurence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPLST</th>\n",
       "      <th>TPLSTLib</th>\n",
       "      <th>VSTEL</th>\n",
       "      <th>VSTELLib</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"13\" valign=\"top\">FR43</th>\n",
       "      <th rowspan=\"13\" valign=\"top\">DC Newlog</th>\n",
       "      <th>BG01</th>\n",
       "      <th>BG02 - Standard</th>\n",
       "      <td>1003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FR20</th>\n",
       "      <th>FR45-Standard</th>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FRD1</th>\n",
       "      <th>FR43-Standard-canalis</th>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FRD2</th>\n",
       "      <th>FR43- Express-Canalis</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FRD3</th>\n",
       "      <th>FR43-Taxi Colis-Canalis</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FRD4</th>\n",
       "      <th>FR43-Export-Canalis</th>\n",
       "      <td>2563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FRI1</th>\n",
       "      <th>FRA8-Chasseneuil-Standard</th>\n",
       "      <td>4952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FRI5</th>\n",
       "      <th>FRA8-Chasseneuil-Pces</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FRM7</th>\n",
       "      <th>FR43- Standard</th>\n",
       "      <td>192950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FRM9</th>\n",
       "      <th>FR43- Express</th>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FRMA</th>\n",
       "      <th>FR43- Taxi colis</th>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FRMB</th>\n",
       "      <th>FR43- Export</th>\n",
       "      <td>685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HU05</th>\n",
       "      <th>HU07-Normal SP Zala Factory</th>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">FR45</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">DC Evreux</th>\n",
       "      <th>FR20</th>\n",
       "      <th>FR45-Standard</th>\n",
       "      <td>371627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FR21</th>\n",
       "      <th>FR45-Parachevement</th>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FR22</th>\n",
       "      <th>FR45-Express</th>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FR24</th>\n",
       "      <th>FR45-Export</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FR26</th>\n",
       "      <th>FR45-Taxi Colis</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FR28</th>\n",
       "      <th>FR45-VAS 1</th>\n",
       "      <td>2466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">HU07</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">HU08-TPP RDC Cent.</th>\n",
       "      <th>HU05</th>\n",
       "      <th>HU07-Normal SP Zala Factory</th>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HU09</th>\n",
       "      <th>HU08-Normal SP Budapest RDC</th>\n",
       "      <td>216173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HU10</th>\n",
       "      <th>HU08-Returns SP Budapest RDC</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HU15</th>\n",
       "      <th>HU08-Express SP Budapest RDC</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HU24</th>\n",
       "      <th>HU08-0 day PP Budapest RDC</th>\n",
       "      <td>2576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             occurence\n",
       "TPLST TPLSTLib           VSTEL VSTELLib                               \n",
       "FR43  DC Newlog          BG01  BG02 - Standard                    1003\n",
       "                         FR20  FR45-Standard                       354\n",
       "                         FRD1  FR43-Standard-canalis               263\n",
       "                         FRD2  FR43- Express-Canalis                 2\n",
       "                         FRD3  FR43-Taxi Colis-Canalis               1\n",
       "                         FRD4  FR43-Export-Canalis                2563\n",
       "                         FRI1  FRA8-Chasseneuil-Standard          4952\n",
       "                         FRI5  FRA8-Chasseneuil-Pces                 4\n",
       "                         FRM7  FR43- Standard                   192950\n",
       "                         FRM9  FR43- Express                       690\n",
       "                         FRMA  FR43- Taxi colis                     80\n",
       "                         FRMB  FR43- Export                        685\n",
       "                         HU05  HU07-Normal SP Zala Factory         253\n",
       "FR45  DC Evreux          FR20  FR45-Standard                    371627\n",
       "                         FR21  FR45-Parachevement                 1057\n",
       "                         FR22  FR45-Express                        278\n",
       "                         FR24  FR45-Export                           1\n",
       "                         FR26  FR45-Taxi Colis                      24\n",
       "                         FR28  FR45-VAS 1                         2466\n",
       "HU07  HU08-TPP RDC Cent. HU05  HU07-Normal SP Zala Factory         162\n",
       "                         HU09  HU08-Normal SP Budapest RDC      216173\n",
       "                         HU10  HU08-Returns SP Budapest RDC         24\n",
       "                         HU15  HU08-Express SP Budapest RDC         45\n",
       "                         HU24  HU08-0 day PP Budapest RDC         2576"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['TPLST', 'TPLSTLib', 'VSTEL', 'VSTELLib']).agg(occurence = ('VSTEL', 'count'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Anomalies in VSTEL; need to be investigated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f'{df.shape[0]:,.0f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['IdSysteme', 'TKNUM', 'SHTYP', 'SHTYPLib', 'TPLST', 'TPLSTLib', 'VSART',\n",
       "       'VSARTLib', 'VSBED', 'VSBEDLib', 'ROUTE', 'ABF', 'TDLNR', 'TDLNRLib',\n",
       "       'TSNUM', 'VSTEL', 'VSTELLib', 'KUNNZ', 'YYEXIDV', 'KUNNR', 'KUNAG',\n",
       "       'Sum_BTGEW', 'Sum_NTGEW', 'GEWEI', 'Sum_VOLUM', 'VOLEH', 'POSNR',\n",
       "       'PARVW', 'KUNNR1', 'PARNR', 'ADRNR', 'ABLAD', 'LAND1', 'NAME1',\n",
       "       'STREET', 'CITY1', 'POST_CODE1', 'REGION', 'COUNTRY'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving raw data to s3\n",
    "df.to_csv(f'{project_path}/raw/sql_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data from NShift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Celonis Hackathon dataset:\n",
    "* Oerebro 2022\n",
    "* Newlog 2022\n",
    "* Evreux 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from s3fs import S3FileSystem\n",
    "s3_fs = S3FileSystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_fs.find('s3://sfgdata/projects/sustainable-transport/raw/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hackathon\n",
    "#data_nshift = pd.read_csv('s3://sfgdata/projects/sustainable-transport/raw/SE_nShift_Oct22.csv', sep='|', decimal=\",\", thousands=\".\")\n",
    "\n",
    "# Newlog and Oerebro\n",
    "#data_nshift = pd.read_csv(f's3://sfgdata/projects/sustainable-transport/raw/Extract_nShift_Newlog_2022.csv')\n",
    "#data_nshift = pd.read_csv(f's3://sfgdata/projects/sustainable-transport/raw/Extract_nShift_Örebro_2022.csv', delimiter = ';', decimal = '.')\n",
    "\n",
    "# Evreux\n",
    "data_nshift = pd.read_csv(f's3://sfgdata/projects/sustainable-transport/raw/Extract_nShift_Evreux_2022.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Do: Data Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(data_nshift, title=\"Pandas Profiling Report\")\n",
    "profile.to_file(\"pandas_profiling_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual exploration: SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique clients\n",
    "df[['Street', 'City','PostCode', 'Country']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entries per DC\n",
    "df.TPLSTLib.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Min Date: ', pd.to_datetime(\n",
    "    df['ABF'], errors='coerce').dropna().min())\n",
    "print('Max Date: ', pd.to_datetime(\n",
    "    df['ABF'], errors='coerce').dropna().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_shipper = df['TPLSTLib'].unique()\n",
    "unique_receiver = df[['Street', 'PostCode', 'City', 'Country']].drop_duplicates().reset_index(drop=True).shape[0]\n",
    "unique_routes = df[['TPLSTLib', 'Street', 'PostCode', 'City', 'Country']].drop_duplicates().reset_index(drop=True).shape[0]\n",
    "\n",
    "# Change to upper or to lower\n",
    "df_upper = df[['Street', 'City', 'PostCode', 'Country']]\n",
    "for i in ['Street', 'City', 'Country']:\n",
    "    df_upper[i] = df_upper[i].str.lower()\n",
    "logger.info(f'Unique receiver  before cleaning: {unique_receiver:,.0f}')\n",
    "logger.info(f'Unique receiver after cleaning: {df_upper.drop_duplicates().shape[0]:,.0f}')\n",
    "logger.info(f'Unique shipper: {unique_shipper}')\n",
    "logger.info(f'Unique routes: {unique_routes:,.0f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual exploration: NShift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nshift.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unique routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_shipper = data_nshift[['Actor']].drop_duplicates().shape[0]\n",
    "\n",
    "unique_receiver = data_nshift[['Receiver address', 'Receiver city', 'Receiver country code',\n",
    "                               'Receiver zip']].drop_duplicates().shape[0]\n",
    "\n",
    "unique_routes = data_nshift[['Actor', 'Receiver address', 'Receiver city', 'Receiver country code', 'Receiver zip']].drop_duplicates().shape[0]\n",
    "\n",
    "print(f'Unique shipper: {unique_shipper}')\n",
    "print(f'Unique receiver: {unique_receiver}')\n",
    "print(f'Unique routes: {unique_routes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nshift.Actor.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to upper or to lower\n",
    "df_upper = data_nshift[['Receiver country code', 'Receiver zip', 'Receiver city','Receiver address']]\n",
    "for i in ['Receiver country code', 'Receiver city','Receiver address']:\n",
    "    df_upper[i] = df_upper[i].str.lower()\n",
    "print(f'Unique receiver before cleaning: {unique_receiver:,.0f}')\n",
    "print(f'Unique receiver before cleaning: {df_upper.drop_duplicates().shape[0]:,.0f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pickup date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(data_nshift['Pickup date'], errors = 'coerce').min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(data_nshift['Pickup date'], errors = 'coerce').max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(data_nshift['Pickup date'], errors = 'coerce').isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nshift['Pickup date'] = pd.to_datetime(data_nshift['Pickup date'], errors = 'coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possible Data Cleaning Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sender weight is Zero\n",
    "df[df.YYBTGEW==0.0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to upper or to lower\n",
    "df_upper = df[['Street', 'City', 'PostCode', 'Country']]\n",
    "for i in ['Street', 'City', 'Country']:\n",
    "    df_upper[i] = df_upper[i].str.lower()\n",
    "df_upper.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Change to only upper/lower addresses: Less unique clients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_column_names = 'nshift_names'\n",
    "\n",
    "client = boto3.client('location')\n",
    "s3 = s3fs.S3FileSystem()\n",
    "with s3.open(f'{project_path}/external/{dict_column_names}.json', 'r') as fp:\n",
    "    dict_names_nshift = json.load(fp)\n",
    "\n",
    "dict_names_nshift = {'Pickup date': 'Pickup date',\n",
    " 'DC name': 'Actor',\n",
    " 'Client name': 'Receiver',\n",
    " 'Address': 'Receiver address',\n",
    " 'Zip': 'Receiver zip',\n",
    " 'City': 'Receiver city',\n",
    " 'Country code': 'Receiver country code',\n",
    " 'Carrier name': 'Carrier',\n",
    " 'Sender weight (kg)': 'Sender weight (kg)',\n",
    " 'Nb of packages': 'Number of packages'}\n",
    "\n",
    "data_nshift = data_preprocessing_nshift(data_nshift, dict_names_nshift)\n",
    "data_nshift['Pickup date'] = pd.to_datetime(data_nshift['Pickup date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_column_names = 'bridge_names'\n",
    "\n",
    "client = boto3.client('location')\n",
    "s3 = s3fs.S3FileSystem()\n",
    "with s3.open(f'{project_path}/external/{dict_column_names}.json', 'r') as fp:\n",
    "    dict_names_bridge = json.load(fp)\n",
    "\n",
    "df_sql = data_preprocessing_bridge(df, dict_names_bridge)\n",
    "df_sql['Pickup date'] = pd.to_datetime(df_sql['Pickup date'])\n",
    "#df_sql = df_sql[df_sql['DC name']=='DC Evreux']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "valids = re.sub(r\"[^A-Za-z]+\", '', my_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_string(x):\n",
    "    if x.isalpha():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_hastag(x):\n",
    "    x = re.sub(\" # \", ' ', x)\n",
    "    x = re.sub(\"# \", ' ', x)\n",
    "    x = re.sub(\"#\", ' ', x)\n",
    "    x = re.sub(\" , \", ' ', x)\n",
    "    x = re.sub(\", \", ' ', x)\n",
    "    x = re.sub(\",\", ' ', x)\n",
    "    x = re.sub(\" - \", ' ', x)\n",
    "    x = re.sub(\"- \", ' ', x)\n",
    "    x = re.sub(\"-\", ' ', x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Address.value_counts()[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Address.iloc['GREMI FLORES, 31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_hastag('GREMI FLORES, 31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Address.apply(lambda x: remove_hastag(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.City.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['City_string']==0].City.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.KUNNZLib.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_names_bridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Validation: SQL vs NShift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"SQL: From {df_sql['Pickup date'].min()} to {df_sql['Pickup date'].max()}\")\n",
    "print(f\"NShift: From {data_nshift['Pickup date'].min()} to {data_nshift['Pickup date'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nshift = data_nshift[(data_nshift['Pickup date']<=\"2022-12-25\")&(data_nshift['Pickup date']>=\"2022-01-04\")]\n",
    "df_sql = df_sql[(df_sql['Pickup date']<=\"2022-12-25\")&(df_sql['Pickup date']>=\"2022-01-04\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nshift['Sender weight (kg)'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql['Sender weight (kg)'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Not the same weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to upper or to lower\n",
    "data_nshift[['Country code', 'Zip', 'City','Address']].drop_duplicates().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to upper or to lower\n",
    "df_sql[['Country code', 'Zip', 'City','Address']].drop_duplicates().shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Not same number of unique receivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In SQL: Shipment on 13-10\n",
    "street = df_sql[(df_sql['Pickup date']>dt.datetime(2022,10,13))&(df_sql['Pickup date']<dt.datetime(2022,10,14))]['Address'].unique()[3]\n",
    "df_sql[(df_sql['Address'] == street)&(df_sql['Pickup date']>dt.datetime(2022,10,13))&(df_sql['Pickup date']<dt.datetime(2022,10,14))][['Pickup date', 'DC name', 'Client name', 'Address', 'Zip', 'City','Country code', 'Carrier name', 'Sender weight (kg)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In NShift: Shipment on 13-10\n",
    "df_nshift[(df_nshift['Address'] == street)&(df_nshift['Pickup date']>dt.datetime(2022,10,12))&(df_nshift['Pickup date']<dt.datetime(2022,10,14))][['Pickup date', 'DC name', 'Client name', 'Address', 'Zip', 'City','Country code', 'Carrier name', 'Sender weight (kg)']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Not the same Weight"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "e874f6c980846f55582070a971d1538cd56fdd96ff8cea3950c345b4fa7ce0be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
